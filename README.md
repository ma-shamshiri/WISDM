# Predicting Activities using Sensor Data

## Introduction
Using sensor data collected from smartphones and smart watches, I'm creating models that could predict a person's activity. I collected this dataset from the UCI Machine Learning Repository.

![WISDM Activities Bubbles]https://github.com/mnnguyen2/WISDM/blob/master/arff_python/WISDM%20Activities.png

## About the dataset
Human activity recognition, or HAR for short, is a broad field of study concerned with identifying the specific movement or action of a person based on sensor data. Being able to sense/ recognize human activity can be a huge asset to many fields including but not limited to healthcare, construction, etc...

Members of the WISDM (Wireless Sensor Data Mining) Lab in the Department of Computer and Information Science of Fordham Unversity collected data from the accelerometer and gyroscope sensors of a smartphone and smartwatch as 51 subjects performed 18 diverse activities of daily living. Each activity was performed for 3 minutes, so that each subject contributed 54 minutes of data. These activities include:

Non-hand-oriented activities: {walking, jogging, stairs, standing, kicking}
Hand-oriented activities (General): {dribbling, playing catch, typing, writing, clapping, brushing teeth, folding clothes}
Hand-oriented activities (eating): {eating pasta, eating soup, eating sandwich, eating chips, drinking}

## About this repository:
In this repository, you should find the following files:
1. arff_python folder. This folder contains the dataset that I used. I rearranged the files so that I could pull from the folder seemlessly from Python. Data source: https://archive.ics.uci.edu/ml/datasets/
2. Python notebook. This notebook contains the models that I built, tuned, and evaluated to predict the 18 activities. 
3. Project Summary Presentation (PDF). This file should give you a good overview of the project and a summary for the model performances. 

